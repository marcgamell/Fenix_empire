\section{Introduction}
An important objective of extreme-scale high performance computing is fault tolerance:
the ability of applications to recover from failures efficiently.
Traditional checkpoint/restart-based techniques face scaling hurdles due to decreasing
mean time between failures, increasing cost of checkpointing, and 
increasing application relaunch time.
Fenix is a framework enabling MPI applications to recover nearly transparently from 
losses of data and/or compute resources manifested as observable errors.
It is based on the premise that the MPI standard itself provide facilities for trapping
and isolating such errors, allowing the application to retain control of remaining unaffected
resources, obviating full program restart.

The current implementation of the Fenix specification \cite{fenixspec} leverages
the  User Level Fault Mitigation (ULFM) \cite{bland2013post} proposal for extension
of the MPI standard.
A prototype implementation of the framework \cite{Gamell:2014} proved successful for
an important production-level simulation code, but concerns have been raised about
overheads incurred by Fenix and ULFM in the absence of failures, as well as of the
applicability of these tools for bulk-synchronous HPC applications.
In this paper we address both concerns through the use of the Parallel Research Kernels
\cite{van2016comparing}, and firmly conclude that ULFM adds no measurable
overhead to applications, not even at very fine granularity.
Moreover, we find that overheads of Fenix are very modest, and can be further reduced.
Finally, our experience shows that Fenix+ULFM are perfectly suitable for tightly coupled
HPC applications.

This paper is structured as follows.
In Section \ref{sec:implem} we briefly describe the salient features of Fenix and ULFM,
and describe the implementation factors that potentially impact performance of MPI applications.
In Section \ref{sec:PRK} we describe the Parallel Research Kernels and the modifications
made to them to incorporate Fenix fault tolerance, including potential pitfalls.
In Section \ref{sec:results} we present measurement data for the kernels,
followed by a summary and conclusions in Section{sec:conclusions}.
